{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "556db3e4-3ca9-4a7e-bab3-1440a30b8ad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils' from '/usr/local/google/home/raulramos/projects/llmrouting/utils.py'>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import Markdown\n",
    "import prompts\n",
    "import utils\n",
    "import json\n",
    "\n",
    "from importlib import reload\n",
    "reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "db218e87-6180-423c-bb67-ee6f91eb0e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"gemini-2.5-flash-preview-05-20\",\n",
    "          'meta/llama-4-scout-17b-16e-instruct-maas']\n",
    "\n",
    "modelA = models[0]\n",
    "modelB = models[1]\n",
    "\n",
    "modelA_response_col = f\"{modelA}::response\"\n",
    "modelB_response_col = f\"{modelB}::response\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "69897667-42aa-4155-a560-5360e5044ad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 9)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_file = 'dolly_15k_extended_small_3k.h5'\n",
    "z = pd.read_hdf(data_file)\n",
    "cols_response = [f\"{model}::response\" for model in models]\n",
    "cols_code = [f\"{model}::code\" for model in models]\n",
    "\n",
    "z = z[(z[cols_code] == 'ok').sum(axis=1) == 2]\n",
    "\n",
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "88bf415e-a420-4eb0-a85c-318a97521104",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(prompts)\n",
    "metric_prompts = {'groundness': prompts.groundness,\n",
    "                  'text_quality': prompts.text_quality,\n",
    "                 'summarization': prompts.summarization,\n",
    "                 'verbosity': prompts.verbosity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc4657b9-4b94-4141-9fc1-c232eb273c54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'prompts' from '/usr/local/google/home/raulramos/projects/llmrouting/prompts.py'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(utils)\n",
    "reload(prompts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64ad2376-e5cd-404c-8150-988d24fa0c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "zmetric_prompts = {k: pd.DataFrame(\n",
    "        [{'prompt': v.format(prompt = zi.context + '\\n\\n' + zi.instruction , responseA = zi[modelA_response_col], responseB = zi[modelB_response_col]),\n",
    "         'id': zi.name,\n",
    "         'response': '',\n",
    "         'code': 'pending'} for _,zi in z.iterrows()]) \\\n",
    "    for k,v in metric_prompts.items() }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b573729-6048-4463-ad52-1f5455a73fba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dolly_15k_extended_small_3k'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_file[:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9fafbcb-8cbb-4c29-a9c3-79e6d8ef832e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric groundness\n",
      "  ok 0, pending 3000, rest 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:   11.9s\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed: 10.4min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed: 15.9min\n",
      "[Parallel(n_jobs=-1)]: Done 632 tasks      | elapsed: 23.0min\n",
      "[Parallel(n_jobs=-1)]: Done 866 tasks      | elapsed: 31.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1136 tasks      | elapsed: 40.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1442 tasks      | elapsed: 51.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed: 64.2min\n",
      "[Parallel(n_jobs=-1)]: Done 2162 tasks      | elapsed: 78.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2576 tasks      | elapsed: 92.8min\n",
      "[Parallel(n_jobs=-1)]: Done 3000 out of 3000 | elapsed: 107.7min finished\n",
      "/tmp/ipykernel_2787853/250754072.py:20: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->Index(['prompt', 'response', 'code'], dtype='object')]\n",
      "\n",
      "  df.to_hdf(f'{data_file[:-3]}_{metric_name}.h5', key='main')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ok 2997, pending 2, rest 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ok 2998, pending 1, rest 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:  4.6min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric text_quality\n",
      "  ok 0, pending 3000, rest 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:   12.3s\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:  7.4min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed: 11.6min\n",
      "[Parallel(n_jobs=-1)]: Done 632 tasks      | elapsed: 16.9min\n",
      "[Parallel(n_jobs=-1)]: Done 866 tasks      | elapsed: 23.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1136 tasks      | elapsed: 29.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1442 tasks      | elapsed: 37.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed: 46.0min\n",
      "[Parallel(n_jobs=-1)]: Done 2162 tasks      | elapsed: 55.5min\n",
      "[Parallel(n_jobs=-1)]: Done 2576 tasks      | elapsed: 66.2min\n",
      "[Parallel(n_jobs=-1)]: Done 3000 out of 3000 | elapsed: 76.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric summarization\n",
      "  ok 0, pending 3000, rest 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    9.9s\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed: 10.5min\n",
      "[Parallel(n_jobs=-1)]: Done 632 tasks      | elapsed: 15.3min\n",
      "[Parallel(n_jobs=-1)]: Done 866 tasks      | elapsed: 21.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1136 tasks      | elapsed: 27.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1442 tasks      | elapsed: 34.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed: 42.5min\n",
      "[Parallel(n_jobs=-1)]: Done 2162 tasks      | elapsed: 51.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2576 tasks      | elapsed: 61.0min\n",
      "[Parallel(n_jobs=-1)]: Done 3000 out of 3000 | elapsed: 70.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ok 2998, pending 1, rest 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ok 2998, pending 1, rest 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric verbosity\n",
      "  ok 0, pending 3000, rest 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:   12.0s\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  9.9min\n",
      "[Parallel(n_jobs=-1)]: Done 632 tasks      | elapsed: 14.5min\n",
      "[Parallel(n_jobs=-1)]: Done 866 tasks      | elapsed: 20.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1136 tasks      | elapsed: 26.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1442 tasks      | elapsed: 33.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed: 41.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2162 tasks      | elapsed: 49.8min\n",
      "[Parallel(n_jobs=-1)]: Done 2576 tasks      | elapsed: 59.1min\n",
      "[Parallel(n_jobs=-1)]: Done 3000 out of 3000 | elapsed: 68.7min finished\n"
     ]
    }
   ],
   "source": [
    "\n",
    "te = utils.GenAI(project='genai-dev-454121', location='us-central1')\n",
    "for metric_name, metric_prompts in zmetric_prompts.items():\n",
    "    print ('metric', metric_name, flush=True)\n",
    "    df = metric_prompts.copy()\n",
    "    while (sum(df.code=='pending')>0):\n",
    "        df_ok      = df[df.code=='ok'].copy()\n",
    "        df_pending = df[df.code=='pending'].copy()\n",
    "        df_rest    = df[~df.code.isin(['ok', 'pending'])].copy()\n",
    "        print (f'  ok {len(df_ok)}, pending {len(df_pending)}, rest {len(df_rest)}', flush=True)  \n",
    "\n",
    "        contents = te.generate_contents(df_pending['prompt'].values, model=\"gemini-2.5-flash-preview-05-20\")\n",
    "\n",
    "        df_pending['response'] = contents['response'].values\n",
    "        df_pending['code'] = contents['code'].values\n",
    "        df_pending['code'] = ['pending' if (i['response'] is None or 'RESOURCE_EXHAUSTED' in i['code'] or i['code'] == 'RefreshError') \\\n",
    "                                          else i[\"code\"] for _,i in df_pending.iterrows()]\n",
    "\n",
    "        df = pd.concat([df_ok, df_pending, df_rest])\n",
    "\n",
    "        df.to_hdf(f'{data_file[:-3]}_{metric_name}.h5', key='main')\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19ca22bc-52d9-4bf2-8c9e-3de9cd401404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>id</th>\n",
       "      <th>response</th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n# Instruction\\nYou are an expert evaluator. ...</td>\n",
       "      <td>12052</td>\n",
       "      <td>## Evaluation\\n\\n### STEP 1: Analyze Response ...</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n# Instruction\\nYou are an expert evaluator. ...</td>\n",
       "      <td>10047</td>\n",
       "      <td>## Evaluation\\n\\n### STEP 1: Analyze Response ...</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n# Instruction\\nYou are an expert evaluator. ...</td>\n",
       "      <td>14743</td>\n",
       "      <td>## Evaluation\\n\\n### STEP 1: Analyze Response ...</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n# Instruction\\nYou are an expert evaluator. ...</td>\n",
       "      <td>8131</td>\n",
       "      <td>```json\\n{\\n \"explanation\": \"STEP 1: Analyze R...</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n# Instruction\\nYou are an expert evaluator. ...</td>\n",
       "      <td>11010</td>\n",
       "      <td>## Evaluation\\n\\n### STEP 1: Analyze Response ...</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\\n# Instruction\\nYou are an expert evaluator. ...</td>\n",
       "      <td>2258</td>\n",
       "      <td>## Evaluation\\n\\n**STEP 1: Analyze Response A ...</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\\n# Instruction\\nYou are an expert evaluator. ...</td>\n",
       "      <td>421</td>\n",
       "      <td>**Explanation:**\\n\\nThe user prompt is \"Write ...</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\\n# Instruction\\nYou are an expert evaluator. ...</td>\n",
       "      <td>2215</td>\n",
       "      <td>Explanation:\\nSTEP 1: Analyze Response A based...</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\\n# Instruction\\nYou are an expert evaluator. ...</td>\n",
       "      <td>10586</td>\n",
       "      <td>*   **STEP 1: Analyze Response A based on the ...</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\\n# Instruction\\nYou are an expert evaluator. ...</td>\n",
       "      <td>4230</td>\n",
       "      <td>*   **STEP 1: Analyze Response A based on the ...</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt     id  \\\n",
       "0  \\n# Instruction\\nYou are an expert evaluator. ...  12052   \n",
       "1  \\n# Instruction\\nYou are an expert evaluator. ...  10047   \n",
       "2  \\n# Instruction\\nYou are an expert evaluator. ...  14743   \n",
       "3  \\n# Instruction\\nYou are an expert evaluator. ...   8131   \n",
       "4  \\n# Instruction\\nYou are an expert evaluator. ...  11010   \n",
       "5  \\n# Instruction\\nYou are an expert evaluator. ...   2258   \n",
       "6  \\n# Instruction\\nYou are an expert evaluator. ...    421   \n",
       "7  \\n# Instruction\\nYou are an expert evaluator. ...   2215   \n",
       "8  \\n# Instruction\\nYou are an expert evaluator. ...  10586   \n",
       "9  \\n# Instruction\\nYou are an expert evaluator. ...   4230   \n",
       "\n",
       "                                            response code  \n",
       "0  ## Evaluation\\n\\n### STEP 1: Analyze Response ...   ok  \n",
       "1  ## Evaluation\\n\\n### STEP 1: Analyze Response ...   ok  \n",
       "2  ## Evaluation\\n\\n### STEP 1: Analyze Response ...   ok  \n",
       "3  ```json\\n{\\n \"explanation\": \"STEP 1: Analyze R...   ok  \n",
       "4  ## Evaluation\\n\\n### STEP 1: Analyze Response ...   ok  \n",
       "5  ## Evaluation\\n\\n**STEP 1: Analyze Response A ...   ok  \n",
       "6  **Explanation:**\\n\\nThe user prompt is \"Write ...   ok  \n",
       "7  Explanation:\\nSTEP 1: Analyze Response A based...   ok  \n",
       "8  *   **STEP 1: Analyze Response A based on the ...   ok  \n",
       "9  *   **STEP 1: Analyze Response A based on the ...   ok  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ae86717d-c716-40b8-825e-43c5cd24c05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(utils)\n",
    "r = {}\n",
    "for m in metric_prompts.keys():\n",
    "    z = pd.read_hdf(f'{data_file[:-3]}_{m}.h5')\n",
    "    r[m] = pd.Series([utils.extract_json_rating(i) for i in z.response.values]).value_counts()\n",
    "r = pd.DataFrame(r).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f4d510b1-ddc9-4ec6-b67d-39138cc69d24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>groundness</th>\n",
       "      <th>text_quality</th>\n",
       "      <th>summarization</th>\n",
       "      <th>verbosity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1.00</th>\n",
       "      <td>804.0</td>\n",
       "      <td>2256.0</td>\n",
       "      <td>1764.0</td>\n",
       "      <td>1967.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-0.80</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-0.75</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-0.50</th>\n",
       "      <td>21.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-0.25</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-0.20</th>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-0.10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.00</th>\n",
       "      <td>1568.0</td>\n",
       "      <td>282.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>139.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.50</th>\n",
       "      <td>6.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.80</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.00</th>\n",
       "      <td>305.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>338.0</td>\n",
       "      <td>509.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       groundness  text_quality  summarization  verbosity\n",
       "-1.00       804.0        2256.0         1764.0     1967.0\n",
       "-0.80         1.0           0.0            0.0        0.0\n",
       "-0.75         5.0           0.0            0.0        0.0\n",
       "-0.50        21.0           7.0            0.0        0.0\n",
       "-0.25         0.0           1.0            0.0        0.0\n",
       "-0.20         3.0           6.0            0.0        0.0\n",
       "-0.10         0.0          12.0            0.0        0.0\n",
       " 0.00      1568.0         282.0          162.0      139.0\n",
       " 0.20         1.0           1.0            0.0        0.0\n",
       " 0.50         6.0          42.0            0.0        0.0\n",
       " 0.80         2.0           0.0            0.0        0.0\n",
       " 1.00       305.0         197.0          338.0      509.0"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "87915dfb-c64d-4bc2-b273-3571f819028b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in metric_prompts.keys():\n",
    "    z = pd.read_hdf(f'{data_file[:-3]}_{m}.h5')\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1b7a63da-e151-4b39-a0af-5e4f72b01658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dolly_15k_extended_small_3k_groundness.h5'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'{data_file[:-3]}_{m}.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "91d8252c-b5f6-4986-9cca-2f635f3d1ed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>id</th>\n",
       "      <th>response</th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n# Instruction\\nYou are an expert evaluator. ...</td>\n",
       "      <td>4132</td>\n",
       "      <td>## Evaluation\\n\\n### STEP 1: Analyze Response ...</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n# Instruction\\nYou are an expert evaluator. ...</td>\n",
       "      <td>1325</td>\n",
       "      <td>Explanation:\\nSTEP 1: Analyze Response A based...</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n# Instruction\\nYou are an expert evaluator. ...</td>\n",
       "      <td>274</td>\n",
       "      <td>explanation:\\nResponse A is fully grounded as ...</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n# Instruction\\nYou are an expert evaluator. ...</td>\n",
       "      <td>1305</td>\n",
       "      <td>## Evaluation\\n\\n### STEP 1: Analyze Response ...</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n# Instruction\\nYou are an expert evaluator. ...</td>\n",
       "      <td>4697</td>\n",
       "      <td>## Evaluation\\n\\n### STEP 1: Analyze Response ...</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>\\n# Instruction\\nYou are an expert evaluator. ...</td>\n",
       "      <td>8697</td>\n",
       "      <td>## Evaluation\\n\\n### STEP 1: Analyze Response ...</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>\\n# Instruction\\nYou are an expert evaluator. ...</td>\n",
       "      <td>7625</td>\n",
       "      <td>```json\\n{\\n \"rating\": 0\\n}\\n```\\n\\n### Explan...</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1550</th>\n",
       "      <td>\\n# Instruction\\nYou are an expert evaluator. ...</td>\n",
       "      <td>14970</td>\n",
       "      <td>## Evaluation\\n\\n### STEP 1: Analyze Response ...</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2146</th>\n",
       "      <td>\\n# Instruction\\nYou are an expert evaluator. ...</td>\n",
       "      <td>493</td>\n",
       "      <td>## Evaluation\\n\\n### STEP 1: Analyze Response ...</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1365</th>\n",
       "      <td>\\n# Instruction\\nYou are an expert evaluator. ...</td>\n",
       "      <td>8003</td>\n",
       "      <td>429 RESOURCE_EXHAUSTED. {'error': {'code': 429...</td>\n",
       "      <td>ClientError</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 prompt     id  \\\n",
       "0     \\n# Instruction\\nYou are an expert evaluator. ...   4132   \n",
       "1     \\n# Instruction\\nYou are an expert evaluator. ...   1325   \n",
       "2     \\n# Instruction\\nYou are an expert evaluator. ...    274   \n",
       "3     \\n# Instruction\\nYou are an expert evaluator. ...   1305   \n",
       "4     \\n# Instruction\\nYou are an expert evaluator. ...   4697   \n",
       "...                                                 ...    ...   \n",
       "2998  \\n# Instruction\\nYou are an expert evaluator. ...   8697   \n",
       "2999  \\n# Instruction\\nYou are an expert evaluator. ...   7625   \n",
       "1550  \\n# Instruction\\nYou are an expert evaluator. ...  14970   \n",
       "2146  \\n# Instruction\\nYou are an expert evaluator. ...    493   \n",
       "1365  \\n# Instruction\\nYou are an expert evaluator. ...   8003   \n",
       "\n",
       "                                               response         code  \n",
       "0     ## Evaluation\\n\\n### STEP 1: Analyze Response ...           ok  \n",
       "1     Explanation:\\nSTEP 1: Analyze Response A based...           ok  \n",
       "2     explanation:\\nResponse A is fully grounded as ...           ok  \n",
       "3     ## Evaluation\\n\\n### STEP 1: Analyze Response ...           ok  \n",
       "4     ## Evaluation\\n\\n### STEP 1: Analyze Response ...           ok  \n",
       "...                                                 ...          ...  \n",
       "2998  ## Evaluation\\n\\n### STEP 1: Analyze Response ...           ok  \n",
       "2999  ```json\\n{\\n \"rating\": 0\\n}\\n```\\n\\n### Explan...           ok  \n",
       "1550  ## Evaluation\\n\\n### STEP 1: Analyze Response ...           ok  \n",
       "2146  ## Evaluation\\n\\n### STEP 1: Analyze Response ...           ok  \n",
       "1365  429 RESOURCE_EXHAUSTED. {'error': {'code': 429...  ClientError  \n",
       "\n",
       "[3000 rows x 4 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9addf6b-de44-470a-b127-85a7734a9665",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p312",
   "language": "python",
   "name": "p312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
